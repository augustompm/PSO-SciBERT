categoria_id;categoria_nome;subcategorias;taxonomia_detalhes;descricao;num_papers
-1;Não Classificado;NULL;NULL;NULL;38
1;Supervised Learning;Classification,Regression,Structured Prediction,Density Estimation,Boundary Estimation,Inductive Methods,Transductive Methods,Problem Transformation,Algorithm Adaptation;Ranking,Learning to Rank,Supervised Learning by Classification,Supervised Learning by Regression,Structured Outputs,Cost-sensitive Learning;"Multi-label Learning (MLL) generalizes traditional classification by allowing instances to have multiple labels. The data are defined as ( D = {(x_i, Y_i)}_{i=1}^n ) with ( x_i in mathcal{X} ) and ( Y_i subseteq mathcal{Y} ), where (mathcal{Y} = {L_1, ldots, L_q}) is the label space, and ( Y_i ) is a variable-sized subset of (mathcal{Y}), represented as a binary vector. The task (mathcal{T} = {mathcal{Y}, f(X)}) involves a prediction function ( f: mathcal{X} ightarrow 2^{mathcal{Y}} ), mapping features to subsets of labels. MLL methods include problem transformation (e.g., converting to binary classification, label ranking, or multiclass classification) and algorithm adaptation (e.g., modifying lazy learning or decision trees). MLL is used when instances belong to multiple categories simultaneously, such as text or image annotation (p. 8â€“9). | One-class Classification (OCC) distinguishes instances of one class (positive) from all others, often used for outlier or novelty detection. The data are either only positive, ( D = D_p = {(x_i, y_i)}_{i=1}^{n_p} ) with ( x_i in mathcal{X} ), ( y_i in mathcal{Y} ), or a combination of positive and unlabeled, ( D = D_p cup D_u ), where ( D_u = {(x_i)}_{i=1}^{n_u} ). The task involves improving a scoring function ( z: mathcal{X} ightarrow mathbb{R} ) to assign novelty scores to test instances, with decisions made via thresholding. Methods include density estimation (estimating the density of positive data) and boundary estimation (defining boundaries around positive data, e.g., one-class SVMs). OCC is applied in anomaly detection, such as in smart homes or image analysis (p. 10â€“11). | Semi-supervised Learning (SSL) uses both labeled and unlabeled data to perform a supervised learning task. The data consist of a labeled part ( D_L = {(x_i, y_i)}_{i=1}^{n_L} ) with ( x_i in mathcal{X} ), ( y_i in mathcal{Y} ), and an unlabeled part ( D_U = {(x_j)}_{j=1}^{n_U} ), forming ( D = D_L cup D_U ). The domain (mathcal{D} = {mathcal{X}, P(X)}) and task (mathcal{T} = {mathcal{Y}, f(X)}) are defined as in SL, with ( f: mathcal{X} ightarrow mathcal{Y} ). SSL improves the prediction function ( f ) by leveraging both ( D_L ) and ( D_U ), applicable to classification or regression. Methods are divided into inductive (generalizing to rules) and transductive (reasoning from training to test cases, often graph-based). SSL is useful when labeled data are scarce, such as in image classification or bioinformatics (p. 9â€“10). | Supervised Learning (SL) requires two components: (i) data and (ii) a task. The data provide information about the instances in the form ( D_s = {(x_i, y_i)}_{i=1}^n ) with ( x_i in mathcal{X} ) and ( y_i in mathcal{Y} ), where (mathcal{X}) is the feature space (e.g., real-valued vectors (mathcal{X} = mathbb{R}^m)) and (mathcal{Y}) is the outcome space. If (mathcal{Y}) is categorical (e.g., (mathcal{Y} = {C_1, C_2})), it leads to classification problems; if (mathcal{Y}) is real-valued (e.g., (mathcal{Y} = mathbb{R})), it leads to regression problems. The task (mathcal{T} = {mathcal{Y}, f(X)}) involves a prediction function ( f: mathcal{X} ightarrow mathcal{Y} ) that maps features to outcomes, either assigning labels (classification) or continuous values (regression). SL is used for predictive tasks where labeled data are available (p. 4â€“5).";545
2;Unsupervised Learning;Clustering,Dimensionality Reduction,Density Estimation,Two-step Methods,Weighting Methods;Cluster Analysis,Anomaly Detection,Mixture Modeling,Topic Modeling,Source Separation,Motif Discovery,Dimensionality Reduction and Manifold Learning;"Positive-unlabeled Learning (PUL) addresses classification with only positive labeled data and unlabeled data, which may belong to any class. The data include ( D_p = {(x_i, y_i)}_{i=1}^{n_p} ) drawn from ( P(x mid Y=+1) ) and ( D_u = {(x_i)}_{i=1}^{n_u} ) from ( P(x) ), forming ( D = D_p cup D_u ). The task (mathcal{T} = {mathcal{Y}, f(X)}) involves a prediction function ( f: mathcal{X} ightarrow mathcal{Y} ) for a binary label space ((mid mathcal{Y} mid = 2)). PUL improves ( f ) using ( D_p ) and ( D_u ), often via two-step methods (identifying negative instances then classifying) or weighting methods (assigning weights to unlabeled data). PUL is used in applications like landslide susceptibility modeling (p. 11â€“12). | Unsupervised Learning (UL) differs from SL in that there is no outcome space (mathcal{Y}). The data assume the form ( D_u = {(x_i)}_{i=1}^n ) with ( x_i in mathcal{X} ), where (mathcal{X}) is the feature space and ( n ) is the sample size. Due to the absence of (mathcal{Y}), no task is defined as in SL, making UL suitable for exploratory data analysis, including unsupervised classification, data discretization, and dimensionality reduction. UL focuses on discovering patterns in unlabeled data, such as grouping similar instances or reducing data complexity (p. 6).";44
3;Reinforcement Learning;Value-based Methods,Policy-based Methods;Sequential Decision Making,Inverse Reinforcement Learning,Apprenticeship Learning,Multi-agent Reinforcement Learning,Adversarial Learning;"Reinforcement Learning (RL) is distinct from SL and UL as it does not use given data in the form of ( D_s ) or ( D_u ). Instead, an agent interacts with an environment via actions that change the environment's state, generating a sequence of actions and states. The agent receives a scalar reinforcement signal (reward or punishment) as feedback, aiming to learn a policy (pi: s_t ightarrow a_t) to maximize the expected return ( V ), the sum of future rewards. RL involves a state transition function ( T: (s_t, a_t) ightarrow s_{t+1} ) and a reward function ( R: s_t ightarrow r_t ). Key challenges include the exploration versus exploitation tradeoff, often modeled as Markov Decision Processes (MDPs) or Partially Observable MDPs (POMDPs). RL is used in applications like robotics and game playing (p. 6â€“7).";24
4;Multi-task Learning;Domain Adaptation,Task Transfer,Joint Task Learning,Task-specific Learning,Similarity-based Methods,Feature-based Methods;Transfer Learning,Lifelong Machine Learning,Learning under Covariate Shift;"Multi-task Learning (MTL) learns multiple tasks simultaneously to improve generalization across them. It involves multiple tasks (mathcal{T}_i = {mathcal{Y}_i, f_i(X)}) with data ( D_{T_i} = {(x_j, y_{i,j})}_{j=1}^{n_i} ) for each task ( i = 1, ldots, m ), forming ( D = D_{T_1} cup ldots cup D_{T_m} ). The goal is to optimize a shared prediction function across tasks, leveraging commonalities. Methods include joint task learning (shared model components) and task-specific learning (task-specific outputs). MTL is used in applications like chemoinformatics and face attribute estimation, where tasks share underlying patterns (p. 14â€“15). | One-shot Learning (OSL) learns from a single or few examples per class, using a training dataset ( D = {(x_i, y_i)}_{i=1}^n ) and a support set ( D_{su} = {(x_{su,j}, y_{su,j})}_{j=1}^k ) with ( k ) small. The task (mathcal{T}_{su} = {mathcal{Y}, f_{su}(X)}) involves a prediction function ( f_{su}: mathcal{X} ightarrow mathcal{Y} ), where (mathcal{Y} 
eq mathcal{Y}_{su}). OSL assumes similarity between training and support data, learning a similarity function ( g ). Methods include similarity-based approaches (e.g., Siamese networks) and feature-based approaches (e.g., Matching Networks). OSL is applied in image recognition and activity recognition with limited data (p. 15â€“16). | Transfer Learning (TL) utilizes information from a source task to improve learning for a target task. It involves a source domain ( D_S = {mathcal{X}_S, P(X_S)} ) and task (mathcal{T}_S = {mathcal{Y}_S, f_S(X)} ), and a target domain ( D_T = {mathcal{X}_T, P(X_T)} ) and task (mathcal{T}_T = {mathcal{Y}_T, f_T(X)} ). TL improves the prediction function ( f_T ) for (mathcal{T}_T) using knowledge from ( D_S ) and (mathcal{T}_S ), assuming differences in domains or tasks. Methods include domain adaptation (aligning feature spaces) and task transfer (e.g., fine-tuning). TL is applied in text classification, activity recognition, and image classification, especially when target data are limited (p. 12â€“13).";49
